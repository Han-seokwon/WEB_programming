{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 웹 관련 라이브러리\n",
    "\n",
    "- ## 웹서버 프로그래밍\n",
    "    - (**Web Framework**)\n",
    "    - Django, Flask\n",
    "    \n",
    "- ## 웹 클라이언트 프로그래밍\n",
    "    - urllib 패키지; 고수준 API 제공\n",
    "    - urllib.parse, urllib.request, urllib.error 등\n",
    "\n",
    "- ## http 패키지\n",
    "    - 저수준 API 제공\n",
    "    - 웹 클라이언트용 API\n",
    "        - http.client 등\n",
    "    - 웹 서버용 API\n",
    "        - http.cookie 등\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 웹 클라이언트 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.parse 모듈\n",
    "- URL의 분해, 조립, 변경, 및 URL 문자 인코딩, 디코딩을 처리하는 함수를 제공\n",
    "- https://docs.python.org/ko/3/library/urllib.parse.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='docs.python.org', path='/ko/3/library/urllib.parse.html', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "result = urlparse('https://docs.python.org/ko/3/library/urllib.parse.html')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paesing(파싱), Paser\n",
    "- 파싱\n",
    "    -  파싱((syntactic) parsing)은 일련의 문자열을 의미있는 토큰(token)으로 분해하고 이들로 이루어진 파스 트리(parse tree)를 만드는 과정을 말한다. https://ko.wikipedia.org/wiki/%EA%B5%AC%EB%AC%B8_%EB%B6%84%EC%84%9D\n",
    "    - 인터넷에 주어진 정보를 가공하여 서버에서 불러올 수 있도록 하는 것\n",
    "- <-> 크롤링\n",
    "    - 조직적, 자동화 된 방법으로 웹을 탐색하며 데이터를 수집하는 작업\n",
    "- parser\n",
    "    - 파싱을 하는 프로그램\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.request 모듈\n",
    "- URL에서 데이터를 가져옴\n",
    "- https://docs.python.org/ko/3.10/library/urllib.request.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "헤더 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection', 'close')\n",
      "('Content-Length', '198409')\n",
      "('Server', 'nginx')\n",
      "('Content-Type', 'text/html')\n",
      "('Last-Modified', 'Wed, 03 Feb 2021 15:00:02 GMT')\n",
      "('ETag', '\"601aba72-30709\"')\n",
      "('X-Clacks-Overhead', 'GNU Terry Pratchett')\n",
      "('Strict-Transport-Security', 'max-age=315360000; includeSubDomains; preload')\n",
      "('Via', '1.1 varnish, 1.1 varnish')\n",
      "('Accept-Ranges', 'bytes')\n",
      "('Date', 'Thu, 04 Feb 2021 00:36:04 GMT')\n",
      "('Age', '17667')\n",
      "('X-Served-By', 'cache-lga21924-LGA, cache-hnd18745-HND')\n",
      "('X-Cache', 'MISS, HIT')\n",
      "('X-Cache-Hits', '0, 1')\n",
      "('X-Timer', 'S1612398964.076692,VS0,VE1')\n",
      "('Vary', 'Accept-Encoding')\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "a=urllib.request.urlopen('https://docs.python.org/ko/3.10/library/urllib.request.html')\n",
    "headers = a.getheaders()\n",
    "for i in headers:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL 상태 코드 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "a=urllib.request.urlopen('https://docs.python.org/ko/3.10/library/urllib.request.html')\n",
    "print(a.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (GET 방식 요청)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"ko\">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "    <title>urllib.request — URL을 열기 위한 확장 가능한 라이브러리 &#8212; Python 3.10.0a5 문서</title>\n",
      "    <link rel=\"stylesheet\" href=\"../_static/pydoctheme.css\" type=\"text/css\" />\n",
      "    <link rel=\"stylesheet\" href=\"../_static/pygments.css\" type=\"text/css\" />\n",
      "    \n",
      "    <script id=\"documentation_options\" data-url_root=\"../\" src=\"..\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "a=urllib.request.urlopen('https://docs.python.org/ko/3.10/library/urllib.request.html', data=None)\n",
    "print(a.read(500).decode('utf8'))# 500바이트 만큼 읽음; 분량조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (POST 방식 요청); 리소스의 생성, 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"email\": \"hanseokwon@han.com\", \n",
      "    \"name\": \"Han seokwon\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Content-Length\": \"41\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"Python-urllib/3.8\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-601d91d3-4f0e15c71986e5c93b165673\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"175.204.249.133\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "url ='http://httpbin.org/post'\n",
    "data = \"name=Han seokwon&email=hanseokwon@han.com\"\n",
    "\n",
    "enCod=requests.get(url).encoding # 해당 사이트의 인코딩 방식\n",
    "req = urllib.request.urlopen(url, bytes(data, encoding=enCod))\n",
    "\n",
    "print(req.read(500).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Request 클래스로 요청 헤더 지정 \n",
    "    - url 인자에 문자열 대신 urllib.request.Request 클래스 지정\n",
    "    - urllib.request.Request 객체를 생성하고 add_header로 헤더를 추가하여 웹 서버로 요청을 보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Fri, 05 Feb 2021 18:54:46 GMT\n",
      "Content-Type: application/json\n",
      "Content-Length: 616\n",
      "Connection: close\n",
      "Server: gunicorn/19.9.0\n",
      "Access-Control-Allow-Origin: *\n",
      "Access-Control-Allow-Credentials: true\n",
      "\n",
      "\n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"email\": \"hanseokwon@han.com\", \n",
      "    \"name\": \"\\ud55c\\uc11d\\uc6d0\", \n",
      "    \"url\": \"https://docs.python.org/ko/3.10/library/urllib.request.html\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Content-Length\": \"137\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Date\": \"05 Feb 2021 18:52:34 GMT\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"Python-urllib/3.8\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-601d9476-7a\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import requests\n",
    "\n",
    "data1 = {\n",
    "    'name' : '한석원',\n",
    "    'email' : 'hanseokwon@han.com',\n",
    "    'url' : 'https://docs.python.org/ko/3.10/library/urllib.request.html'\n",
    "}\n",
    "\n",
    "url ='http://httpbin.org/post'\n",
    "encData=urllib.parse.urlencode(data1)\n",
    "enCod=requests.get(url).encoding # 해당 사이트의 인코딩 방식\n",
    "\n",
    "req = urllib.request.Request(url, bytes(encData, encoding=enCod))\n",
    "req.add_header('Date', '05 Feb 2021 18:52:34 GMT')\n",
    "a = urllib.request.urlopen(req)\n",
    "print(a.info())\n",
    "print(a.read(500).decode(enCod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.request 파싱 예제\n",
    "- 특정 웹사이트에서 이미지만을 검색하여 그 리스트를 보여주는 코드\n",
    "- HTMLParser 클래스 https://docs.python.org/ko/3/library/html.parser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " https://www.google.co.kr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE 1 : /images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\n",
      "IMAGE 2 : /textinputassistant/tia.png\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from html.parser import HTMLParser # HTMLParser 클래스는 HTML 문서를 파싱하는데 사용되는 클래스\n",
    "\n",
    "# HTMLParser 클래스는 아래와 같이 상속받는 클래스를 정의하여 사용함\n",
    "\n",
    "class Image_Parser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs): # HTML의 시작태그를 핸들링하는 메소드를 오버라이드\n",
    "        # (입력 인자) 예: <img src='cat.jpg'>\n",
    "        # tag : 소문자로 변환된 태그의 이름 / img\n",
    "        # attrs : 태그의 (name, value) 쌍의 리스트 / [('src', 'cat.jpg')]\n",
    "        if tag == 'img':\n",
    "            if not hasattr(self, 'result'): # hasattr 'result'라는 변수가 있는지 확인하기; 파이썬 내장 함수\n",
    "                self.result = []\n",
    "            for name, value in attrs: # <img src> 속성을 찾으면 속성값을 self.result에 추가\n",
    "                if name == 'src':\n",
    "                    self.result.append(value)\n",
    "\n",
    "def parse_image(data): # HTML 문장이 주어지면 HTMLParser 클래스를 사용하여 이미지를 찾고, 그 리스트를 출력해주는 함수\n",
    "    # data는 HTML 문장\n",
    "    parser = Image_Parser()\n",
    "    parser.feed(data)\n",
    "    data_set= [x for x in parser.result]\n",
    "    return data_set\n",
    "\n",
    "def Search_image(url):\n",
    "\n",
    "    a= urllib.request.urlopen(url) # urlopen 함수로 해당 사이트의 페이지 내용을 가져옴\n",
    "    # print(a.info())\n",
    "    charset = a.info().get_param('charset') # 해당 사이트의 인코딩 방식을 찾음\n",
    "    data = a.read().decode(charset) # 해당 사이트의 인코딩 방식으로 그것으로 디코딩\n",
    "\n",
    "\n",
    "    data_set = parse_image(data) # 이미지 파싱\n",
    "\n",
    "\n",
    "    img_num=1\n",
    "    for i in data_set:\n",
    "        print('IMAGE %d :'%(img_num),i)\n",
    "        img_num+=1\n",
    "\n",
    "# https://www.google.co.kr\n",
    "url = input()\n",
    "Search_image(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beautifulSoup4를 사용해 위의 예제 구현\n",
    "- beautifulSoup4가 더 간단함\n",
    "- BeautifulSoup(HTML 내용, 파서)\n",
    "    - 파서 종류 https://brownbears.tistory.com/414\n",
    "    - html.parser : 얘가 무난함\n",
    "    - lxml\n",
    "    - lxml-xml\n",
    "    - 등등\n",
    "- https://wikidocs.net/85739\n",
    "- ***- requests 모듈은 urllib.request와 유사하게 HTTP요청을 보냄***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE 1 : /images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\n",
      "IMAGE 2 : /textinputassistant/tia.png\n"
     ]
    }
   ],
   "source": [
    "import requests #\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "def parse_image(data):\n",
    "    soup = BeautifulSoup(data, 'html.parser') # HTML 문장, Parser\n",
    "    imgTaglist = soup.find_all('img') # 찾고자 하는 태그를 모두 가져옴; 그 태그 안에 있는 태그들도\n",
    "    # x.attrs는 딕셔너리로 속성값을 반환함\n",
    "    # 예: {'img' : 'cat.jpg, 'alt' : 'cat'}\n",
    "    data_set = [x.attrs['src'] for x in imgTaglist]\n",
    "\n",
    "    return  data_set\n",
    "\n",
    "\n",
    "def Search_img(url):\n",
    "\n",
    "    req = requests.get(url)\n",
    "    # print(req.text) # 읽어온 HTML 코드\n",
    "    charset = req.encoding # 해당 사이트의 인코딩 방식을 찾음\n",
    "    data = req.content.decode(charset)# 해당 사이트의 인코딩 방식으로 그것으로 디코딩\n",
    "\n",
    "    data_set = parse_image(data)\n",
    "    img_num=1\n",
    "    for i in data_set:\n",
    "        print('IMAGE %d :'%(img_num),i)\n",
    "        img_num+=1\n",
    "\n",
    "url = 'https://www.google.co.kr'\n",
    "Search_img(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## http.client\n",
    "- urllib.request 모듈에서 처리하기 힘든 기능을 구현할 때 사용\n",
    "     - HEAD, PUT 방식으로 요청도 가능\n",
    "- urllib.request로 만든 기능을 http.client로 동일하게 만들 수 있음\n",
    "- http.client 모듈 사용 순서\n",
    "    - 1. conn = http.client.HTTPSConnection(\"www.python.org\") # 연결객체생성\n",
    "        - 인자는 url이 아닌 호스트 이름으로 해야함\n",
    "    - 2. conn.request(\"요청방식\", \"/\") # 요청방식: GET, POST, HEAD, PUT\n",
    "    - 3. resp = conn.getresponse() # 응답 객체 생성\n",
    "    - 4. resp.read() # 응답 데이터 읽기\n",
    "    - 5. resp.close() # 연결 닫기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 호스트\n",
    "- 웹서버의 IP주소\n",
    "- 호스트 명은 네트워크에 연결된 장치 또는 서버들에 부여되는 고유한 이름으로 호스트 명은 IP 주소나 MAC 주소와 같은 기계적인 이름을 대신하여 일반인이 쉽게 읽고 이해할 수 있는 이름으로 만들어집니다, http://www.codns.com/b/B05-195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http.client GET 방식 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status: 200 OK\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>httpbin.org</title>\n",
      "    <link href=\"https://fonts.googleapis.com/css?family=Open+Sans:400,700|Source+Code+Pro:300,600|Titillium+Web:400,600,700\"\n",
      "        rel=\"stylesheet\">\n",
      "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/flasgger_static/swagger-ui.css\">\n",
      "    <link rel=\"icon\" type=\"image/png\" href=\"/static/favicon.ico\" sizes=\"64x64 32x32 16x16\" />\n",
      "    <style>\n",
      "        html {\n",
      "            box-sizing: border-box;\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "from http.client import HTTPConnection\n",
    "\n",
    "# 연결 객체 생성\n",
    "\n",
    "conn = HTTPConnection('httpbin.org')\n",
    "\n",
    "# GET 요청\n",
    "conn.request('GET', '/')\n",
    "# 응답 객체 생성\n",
    "resp = conn.getresponse()\n",
    "# 응답 결과\n",
    "print('HTTP status:', resp.status , resp.reason)\n",
    "\n",
    "# 응답 데이터를 읽음; 500까지만\n",
    "data = resp.read(500)\n",
    "print(data.decode())\n",
    "\n",
    "\n",
    "conn.close() # 연결을 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http.client POST 방식 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status: 200 OK\n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"language=python&name=Han+seokwon\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Content-Length\": \"32\", \n",
      "    \"Content-Type\": \"application/\", \n",
      "    \"Date\": \"05 Feb 2021 18:52:34 GMT\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-601d9705-18ce349106e77ca7785a1331\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"175.204.249.133\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from http.client import HTTPConnection\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# 연결 객체 생성\n",
    "conn = HTTPConnection('httpbin.org')\n",
    "\n",
    "# POST 요청으로 보낼 파라미터에 대해 URL 인코딩\n",
    "params = urlencode({\n",
    "    'language' : 'python',\n",
    "    'name' : 'Han seokwon'\n",
    "})\n",
    "# POST 요청으로 보낼 헤더를 딕셔너리로 지정\n",
    "headers = {\n",
    "    'Content-Type' : 'application/',\n",
    "    'Date': '05 Feb 2021 18:52:34 GMT'\n",
    "}\n",
    "\n",
    "# POST 요청\n",
    "# request(method, url, body, headers); method와 url은 필수 인자\n",
    "conn.request('POST', 'http://httpbin.org//post', params, headers)\n",
    "\n",
    "# 응답 객체 생성\n",
    "resp = conn.getresponse()\n",
    "# 응답 결과\n",
    "print('HTTP status:', resp.status , resp.reason)\n",
    "\n",
    "#\n",
    "data = resp.read()\n",
    "print(data.decode('utf-8'))\n",
    "\n",
    "\n",
    "conn.close() # 연결을 닫음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http.client HEAD 방식 요청; 리소스의 헤더 취득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status: 200 OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from http.client import HTTPConnection\n",
    "\n",
    "# 연결 객체 생성\n",
    "\n",
    "conn = HTTPConnection('httpbin.org')\n",
    "\n",
    "# HEAD 요청\n",
    "conn.request('HEAD', '/')\n",
    "# 응답 객체 생성\n",
    "resp = conn.getresponse()\n",
    "# 응답 결과\n",
    "print('HTTP status:', resp.status , resp.reason)\n",
    "\n",
    "# 헤더만 가져왔으므로 응답에이터는 없음\n",
    "data = resp.read(500)\n",
    "print(data.decode())\n",
    "\n",
    "\n",
    "conn.close() # 연결을 닫음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http.client PUT 방식 요청; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status: 200 OK\n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"language=python&name=Han+seokwon\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Content-Length\": \"32\", \n",
      "    \"Content-Type\": \"application/\", \n",
      "    \"Date\": \"05 Feb 2021 18:52:34 GMT\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-601d970a-35ace62715312e8f22aef2db\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"175.204.249.133\", \n",
      "  \"url\": \"http://httpbin.org/put\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from http.client import HTTPConnection\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# 연결 객체 생성\n",
    "conn = HTTPConnection('httpbin.org')\n",
    "\n",
    "# POST 요청으로 보낼 파라미터에 대해 URL 인코딩\n",
    "params = urlencode({\n",
    "    'language' : 'python',\n",
    "    'name' : 'Han seokwon'\n",
    "})\n",
    "# POST 요청으로 보낼 헤더를 딕셔너리로 지정\n",
    "headers = {\n",
    "    'Content-Type' : 'application/',\n",
    "    'Date': '05 Feb 2021 18:52:34 GMT'\n",
    "}\n",
    "\n",
    "# PUT 요청\n",
    "# request(method, url, body, headers); method와 url은 필수 인자\n",
    "conn.request('PUT', 'http://httpbin.org/put', params, headers)\n",
    "\n",
    "# 응답 객체 생성\n",
    "resp = conn.getresponse()\n",
    "# 응답 결과\n",
    "print('HTTP status:', resp.status , resp.reason)\n",
    "\n",
    "#\n",
    "data = resp.read()\n",
    "print(data.decode('utf-8'))\n",
    "\n",
    "\n",
    "conn.close() # 연결을 닫음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http.client 예제\n",
    "- 특정 사이트에서 이미지만을 찾아 다운로드하는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download:  https://www.google.com/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\n",
      "Download:  https://www.google.com/textinputassistant/tia.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import urljoin, urlunparse\n",
    "from urllib.request import urlretrieve\n",
    "from http.client import HTTPConnection\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class Image_Parser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs): # HTML의 시작태그를 핸들링하는 메소드를 오버라이드\n",
    "        # (입력 인자) 예: <img src='cat.jpg'>\n",
    "        # tag : 소문자로 변환된 태그의 이름 / img\n",
    "        # attrs : 태그의 (name, value) 쌍의 리스트 / [('src', 'cat.jpg')]\n",
    "        if tag == 'img':\n",
    "            if not hasattr(self, 'result'): # hasattr 'result'라는 변수가 있는지 확인하기; 파이썬 내장 함수\n",
    "                self.result = []\n",
    "            for name, value in attrs: # <img src> 속성을 찾으면 속성값을 self.result에 추가\n",
    "                if name == 'src':\n",
    "                    self.result.append(value)\n",
    "\n",
    "def download_img(url, data):\n",
    "    parser = Image_Parser()\n",
    "    parser.feed(data)\n",
    "\n",
    "    data_set = [x for x in parser.result]\n",
    "\n",
    "    for i in data_set:\n",
    "        img_url = urljoin(url, i) # URL + 이미지 src -> 이미지 소스\n",
    "\n",
    "        # 해당 URL의 basename 예: D:\\WEB_study\\text.txt -(basename)-> test.txt\n",
    "        basename = os.path.basename(img_url)\n",
    "\n",
    "        # 이미지를 저장할 파일과 이미지의 basename을 연결\n",
    "        target_file = os.path.join('python_web_library/image1', basename)\n",
    "\n",
    "        print('Download: ',img_url)\n",
    "        urlretrieve(img_url, target_file) #이미지 소스를 가져와 target_file로 저장\n",
    "\n",
    "def Search_Download_img(host):\n",
    "\n",
    "    # 연결 객체 생성\n",
    "    conn = HTTPConnection(host)\n",
    "\n",
    "    conn.request('GET','')\n",
    "\n",
    "    # 응답 객체 생성\n",
    "    resp = conn.getresponse()\n",
    "\n",
    "    # 응답 데이터 읽기\n",
    "    charset = resp.msg.get_param('charset')  # 해당 사이트의 인코딩 방식을 찾음\n",
    "    data = resp.read().decode(charset)  # 해당 사이트의 인코딩 방식으로 그것으로 디코딩\n",
    "    conn.close() # 연결을 닫음\n",
    "\n",
    "    # urlunparse()는 6개의 URL 요소를 튜플로 받아 연결한 URL을 리턴함\n",
    "    # urlparse()와 반대; URL을 6개로 분리하여 튜플로 반환\n",
    "    url = urlunparse(('https', host, '','','',''))\n",
    "\n",
    "    # 이미지 다운로드드\n",
    "    download_img(url, data)\n",
    "\n",
    "host = 'www.google.com'\n",
    "Search_Download_img(host)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beautifulSoup4를 사용해 위의 예제 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download:  https://www.google.com/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\n",
      "Download:  https://www.google.com/textinputassistant/tia.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def parse_image(data):\n",
    "    soup = BeautifulSoup(data, 'html.parser') # HTML 문장, Parser\n",
    "    imgTaglist = soup.find_all('img') # 찾고자 하는 태그를 모두 가져옴; 그 태그 안에 있는 태그들도\n",
    "    # x.attrs는 딕셔너리로 속성값을 반환함\n",
    "    # 예: {'img' : 'cat.jpg, 'alt' : 'cat'}\n",
    "    data_set = [x.attrs['src'] for x in imgTaglist]\n",
    "\n",
    "    return  data_set\n",
    "\n",
    "def download_img(url, data_set):\n",
    "\n",
    "    for i in data_set:\n",
    "        img_url = urljoin(url, i) # URL + 이미지 src -> 이미지 소스\n",
    "\n",
    "        # 해당 URL의 basename 예: D:\\WEB_study\\text.txt -(basename)-> test.txt\n",
    "        basename = os.path.basename(img_url)\n",
    "\n",
    "        # 이미지를 저장할 파일과 이미지의 basename을 연결\n",
    "        target_file = os.path.join('python_web_library/image1', basename)\n",
    "\n",
    "        print('Download: ',img_url)\n",
    "        req = requests.get(img_url)\n",
    "        # with as 구문으로 파일을 해당 구문에서만 실행시키고 바로 닫을 수 있음\n",
    "        with open(target_file, 'wb') as file: # wb = write + binary(bytes 객체로 읽고 쓰기 수행)\n",
    "            file.write(req.content) # req.content는 bytes로 되어 있음\n",
    "\n",
    "def Search_Download_img(url):\n",
    "\n",
    "    req = requests.get(url)\n",
    "    charset = req.encoding  # 해당 사이트의 인코딩 방식을 찾음\n",
    "    data = req.content.decode(charset)  # 해당 사이트의 인코딩 방식으로 그것으로 디코딩\n",
    "\n",
    "    data_set = parse_image(data)\n",
    "\n",
    "    download_img(url, data_set)\n",
    "\n",
    "url = 'https://www.google.com/'\n",
    "Search_Download_img(url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_web_venv",
   "language": "python",
   "name": "python_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
